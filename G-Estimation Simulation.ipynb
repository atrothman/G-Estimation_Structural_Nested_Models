{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "######################\n",
    "## import libraries ##\n",
    "######################\n",
    "import pandas as pd\n",
    "import numpy as np    \n",
    "np.random.seed(108156571)\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulate_dataset(n=100000, C1=1):\n",
    "    \n",
    "    ## A: dichotomous\n",
    "    ## C1: continuous (with squared term) -> only effect modification\n",
    "    ## C2: discrete -> only confouding\n",
    "        \n",
    "    A_split = 0.4\n",
    "    C2_split = 0.35\n",
    "\n",
    "    df_A1 = pd.DataFrame()\n",
    "    df_A1['A'] = np.ones(int(n*A_split))\n",
    "    df_A1['C2'] = np.random.uniform(0, 1, df_A1.shape[0])\n",
    "    df_A1.loc[df_A1['C2']<C2_split, 'C2'] = 0\n",
    "    df_A1.loc[df_A1['C2']>=C2_split, 'C2'] = 1\n",
    "        \n",
    "        \n",
    "    df_A0 = pd.DataFrame()\n",
    "    df_A0['A'] = np.zeros(int(n*(1-A_split)))\n",
    "    df_A0['C2'] = np.random.uniform(0, 1, df_A0.shape[0])\n",
    "    df_A0.loc[df_A0['C2']<(1-C2_split), 'C2'] = 0\n",
    "    df_A0.loc[df_A0['C2']>=(1-C2_split), 'C2'] = 1\n",
    "    \n",
    "    df = pd.concat([df_A0, df_A1], axis=0).reset_index(drop=True) \n",
    "    df['C1'] = np.random.normal(2.5, 1, df.shape[0])\n",
    "    df['C1_squared'] = df['C1']*df['C1']\n",
    "    df['C1_sin'] = 3*np.sin(df['C1'])\n",
    "    df['C1_squared_sin_interaction'] = df['C1_squared']*df['C1_sin']\n",
    "    df['error'] = np.random.normal(0, 0.25, df.shape[0])     \n",
    "    \n",
    "    B0 = -0.23\n",
    "    B1 = 1.23\n",
    "    B2 = 1.56\n",
    "    B3 = 1.42\n",
    "    B4 = 2.31\n",
    "    B5 = -0.43\n",
    "    B6 = 0.52\n",
    "    B7 = 1.09\n",
    "    \n",
    "    df['Y'] = B0 + (B1*df['A']) + (B2*df['C1']) + (B3*df['C1_squared']) + (B4*df['C1_sin']) + (B5*df['C1_squared_sin_interaction']) + (B6*df['C2']) + (B7*df['A']*df['C1']) + df['error']\n",
    "    \n",
    "    print(\"In the marginal Causal DAG, there is confounding by C2 and effect modification by C1 \\n\")\n",
    "    print(\"The true outcome model is:\")\n",
    "    print('E[Y|A,C1,C2] = ' + str(B0) + ' + ' + str(B1) + '*A + ' + str(B2) + '*C1 + ' + str(B3) + '*C1^2 + ' + str(B4) + '*sin(C1) + ' + str(B5) + '*C1^2*sin(C1) + ' + str(B6) + '*C2 + ' + str(B7) + '*A*C1')\n",
    "    print('\\n')\n",
    "    print('The true Mean Causal Effect Difference under intervention a=1 and a=0 within levels of C1=' + str(C1) + ' is:')\n",
    "    print('E[Y(a=1)-Y(a=0)|C1=' + str(C1) + '] = ' + str(B1 + (B7*C1)))\n",
    "   \n",
    "    return(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In the marginal Causal DAG, there is confounding by C2 and effect modification by C1 \n",
      "\n",
      "The true outcome model is:\n",
      "E[Y|A,C1,C2] = -0.23 + 1.23*A + 1.56*C1 + 1.42*C1^2 + 2.31*sin(C1) + -0.43*C1^2*sin(C1) + 0.52*C2 + 1.09*A*C1\n",
      "\n",
      "\n",
      "The true Mean Causal Effect Difference under intervention a=1 and a=0 within levels of C1=0.5 is:\n",
      "E[Y(a=1)-Y(a=0)|C1=0.5] = 1.775\n"
     ]
    }
   ],
   "source": [
    "## get simulated dataset\n",
    "df_original = simulate_dataset(n=200000, C1=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "###############################################\n",
    "## fit and return standardized outcome model ##\n",
    "###############################################\n",
    "def fit_standardized_outcome_model(df, model_string, C1, fit_bounds=True, print_result=True):\n",
    "    df_original = df.copy()\n",
    "    df_A0 = df_original.copy()\n",
    "    df_A1 = df_original.copy()\n",
    "    \n",
    "    df_A0['A'] = 0\n",
    "    df_A0['C1'] = C1\n",
    "    df_A0['C1_squared'] = df_A0['C1']*df_A0['C1']\n",
    "    df_A0['C1_sin'] = 3*np.sin(df_A0['C1'])\n",
    "    df_A0['C1_squared_sin_interaction'] = df_A0['C1_squared']*df_A0['C1_sin']\n",
    "    \n",
    "    df_A1['A'] = 1\n",
    "    df_A1['C1'] = C1\n",
    "    df_A1['C1_squared'] = df_A1['C1']*df_A1['C1']\n",
    "    df_A1['C1_sin'] = 3*np.sin(df_A1['C1'])\n",
    "    df_A1['C1_squared_sin_interaction'] = df_A1['C1_squared']*df_A1['C1_sin']\n",
    "\n",
    "    outcome_model = smf.ols(formula=model_string, data=df).fit()\n",
    "    df_A0['Y_fit'] = outcome_model.predict(df_A0)\n",
    "    df_A1['Y_fit'] = outcome_model.predict(df_A1)\n",
    "    mean_unexposed = df_A0['Y_fit'].mean()\n",
    "    mean_exposed = df_A1['Y_fit'].mean()\n",
    "    effect_difference = mean_exposed - mean_unexposed\n",
    "        \n",
    "    if(fit_bounds):\n",
    "        effect_difference_list = []\n",
    "        for i in range(0, 100):\n",
    "            df_sub = df_original.sample(n=df_original.shape[0], replace=True)\n",
    "            df_A0_sub = df_sub.copy()\n",
    "            df_A1_sub = df_sub.copy()\n",
    "            \n",
    "            df_A0_sub['A'] = 0\n",
    "            df_A0_sub['C1'] = C1\n",
    "            df_A0_sub['C1_squared'] = df_A0_sub['C1']*df_A0_sub['C1']\n",
    "            df_A0_sub['C1_sin'] = 3*np.sin(df_A0_sub['C1'])\n",
    "            df_A0_sub['C1_squared_sin_interaction'] = df_A0_sub['C1_squared']*df_A0_sub['C1_sin']\n",
    "            \n",
    "            df_A1_sub['A'] = 1\n",
    "            df_A1_sub['C1'] = C1\n",
    "            df_A1_sub['C1_squared'] = df_A1_sub['C1']*df_A1_sub['C1']\n",
    "            df_A1_sub['C1_sin'] = 3*np.sin(df_A1_sub['C1'])\n",
    "            df_A1_sub['C1_squared_sin_interaction'] = df_A1_sub['C1_squared']*df_A1_sub['C1_sin']\n",
    "            \n",
    "            OM_sub = smf.ols(formula=model_string, data=df_sub).fit()\n",
    "            df_A0_sub['Y_fit'] = OM_sub.predict(df_A0_sub)\n",
    "            df_A1_sub['Y_fit'] = OM_sub.predict(df_A1_sub)\n",
    "            mean_unexposed_sub = df_A0_sub['Y_fit'].mean()\n",
    "            mean_exposed_sub = df_A1_sub['Y_fit'].mean()\n",
    "            effect_difference_sub = mean_exposed_sub - mean_unexposed_sub\n",
    "            effect_difference_list.append(effect_difference_sub)\n",
    "            del df_sub, df_A0_sub, df_A1_sub, OM_sub, mean_unexposed_sub, mean_exposed_sub, effect_difference_sub\n",
    "   \n",
    "        variance = np.var(effect_difference_list)\n",
    "        standard_error = np.sqrt(variance)\n",
    "        bound_size = 1.96*standard_error\n",
    "        lower_bound = effect_difference - bound_size\n",
    "        upper_bound = effect_difference + bound_size\n",
    "    \n",
    "    if(print_result):\n",
    "        print(outcome_model.summary())\n",
    "        print(\"The standardized mean in those with A=0 and C1=\" + str(C1) +\" is: \" + str(mean_unexposed))\n",
    "        print(\"The standardized mean in those with A=1 and C1=\" + str(C1) +\" is: \" + str(mean_exposed))\n",
    "        if(fit_bounds):\n",
    "            print(\"The standardized effect difference with C1=\" + str(C1) +\" is \" + str(effect_difference) + \" with 95% CI (\" + str(lower_bound) + ' , ' + str(upper_bound) + ')')\n",
    "        else:\n",
    "            print(\"The standardized effect difference with C1=\" + str(C1) + \" is \" + str(effect_difference))\n",
    "    \n",
    "    return(df, outcome_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                      Y   R-squared:                       1.000\n",
      "Model:                            OLS   Adj. R-squared:                  1.000\n",
      "Method:                 Least Squares   F-statistic:                 7.241e+07\n",
      "Date:                Tue, 15 Dec 2020   Prob (F-statistic):               0.00\n",
      "Time:                        12:30:44   Log-Likelihood:                -6440.0\n",
      "No. Observations:              200000   AIC:                         1.290e+04\n",
      "Df Residuals:                  199992   BIC:                         1.298e+04\n",
      "Df Model:                           7                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================================\n",
      "                                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "----------------------------------------------------------------------------------------------\n",
      "Intercept                     -0.2341      0.004    -65.471      0.000      -0.241      -0.227\n",
      "A                              1.2305      0.003    397.969      0.000       1.224       1.237\n",
      "C1                             1.5610      0.004    434.572      0.000       1.554       1.568\n",
      "C1_squared                     1.4201      0.001   1462.192      0.000       1.418       1.422\n",
      "C1_sin                         2.3105      0.001   2671.685      0.000       2.309       2.312\n",
      "C1_squared_sin_interaction    -0.4299   9.75e-05  -4409.689      0.000      -0.430      -0.430\n",
      "C2                             0.5202      0.001    444.135      0.000       0.518       0.523\n",
      "A:C1                           1.0897      0.001    956.363      0.000       1.087       1.092\n",
      "==============================================================================\n",
      "Omnibus:                        0.658   Durbin-Watson:                   1.993\n",
      "Prob(Omnibus):                  0.720   Jarque-Bera (JB):                0.655\n",
      "Skew:                           0.004   Prob(JB):                        0.721\n",
      "Kurtosis:                       3.002   Cond. No.                         155.\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "The standardized mean in those with A=0 and C1=0.5 is: 4.314202877691639\n",
      "The standardized mean in those with A=1 and C1=0.5 is: 6.089578604476575\n",
      "The standardized effect difference with C1=0.5 is 1.7753757267849357 with 95% CI (1.770226691240206 , 1.7805247623296654)\n"
     ]
    }
   ],
   "source": [
    "## Standardization via the g-formula with correctly specified Outcome model\n",
    "_, OM_CS = fit_standardized_outcome_model(df_original.copy(), model_string='Y ~ A + C1 + C1_squared + C1_sin + C1_squared_sin_interaction + C2 + A*C1', C1=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                      Y   R-squared:                       0.781\n",
      "Model:                            OLS   Adj. R-squared:                  0.781\n",
      "Method:                 Least Squares   F-statistic:                 1.787e+05\n",
      "Date:                Tue, 15 Dec 2020   Prob (F-statistic):               0.00\n",
      "Time:                        12:31:45   Log-Likelihood:            -6.3824e+05\n",
      "No. Observations:              200000   AIC:                         1.276e+06\n",
      "Df Residuals:                  199995   BIC:                         1.277e+06\n",
      "Df Model:                           4                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "Intercept     -9.3879      0.047   -201.192      0.000      -9.479      -9.296\n",
      "A              1.0750      0.073     14.765      0.000       0.932       1.218\n",
      "C1            10.4411      0.017    615.821      0.000      10.408      10.474\n",
      "C2             0.4690      0.028     17.004      0.000       0.415       0.523\n",
      "A:C1           1.1554      0.027     43.065      0.000       1.103       1.208\n",
      "==============================================================================\n",
      "Omnibus:                    57216.051   Durbin-Watson:                   1.998\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):           152782.810\n",
      "Skew:                           1.548   Prob(JB):                         0.00\n",
      "Kurtosis:                       5.957   Cond. No.                         20.1\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "The standardized mean in those with A=0 and C1=0.5 is: -3.947189022554274\n",
      "The standardized mean in those with A=1 and C1=0.5 is: -2.294511922724974\n",
      "The standardized effect difference with C1=0.5 is 1.6526770998292997 with 95% CI (1.4681702357375714 , 1.837183963921028)\n"
     ]
    }
   ],
   "source": [
    "## Standardization via the g-formula with incorrectly specified Outcome model\n",
    "_, OM_IS = fit_standardized_outcome_model(df_original.copy(), model_string='Y ~ A + C1 + C2 + A*C1', C1=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "##############################################\n",
    "## fit and return Marginal Strucutral Model ##\n",
    "##############################################\n",
    "def fit_MSM_model(df, model_string, MSM_string, C1, fit_bounds=True, print_result=True):\n",
    "    PS_model = smf.glm(model_string, data=df, family=sm.families.Binomial()).fit()\n",
    "    df['Propensity_Score'] = PS_model.predict(df)\n",
    "    Marg_Prob_Intervention = df.loc[df['A']==1, :].reset_index(drop=True).shape[0] / df.shape[0]\n",
    "    df['Unstabalized_Weights'] = None\n",
    "    df.loc[df['A']==1, 'Unstabalized_Weights'] = 1 / (df.loc[df['A']==1, 'Propensity_Score'])\n",
    "    df.loc[df['A']==0, 'Unstabalized_Weights'] = 1 / (1 - df.loc[df['A']==0, 'Propensity_Score'])\n",
    "    df['Stabalized_Weights'] = None\n",
    "    df.loc[df['A']==1, 'Stabalized_Weights'] = (Marg_Prob_Intervention) / (df.loc[df['A']==1, 'Propensity_Score'])\n",
    "    df.loc[df['A']==0, 'Stabalized_Weights'] = (1 - Marg_Prob_Intervention) / (1 - df.loc[df['A']==0, 'Propensity_Score'])\n",
    "    MSM = smf.wls(MSM_string, data=df, weights=np.array(df['Stabalized_Weights'], dtype=np.float64)).fit()\n",
    "    #print(MSM.summary())\n",
    "    \n",
    "    df_A0 = pd.DataFrame()\n",
    "    df_A0['A'] = [0]\n",
    "    df_A0['C1'] = C1\n",
    "    df_A0['C1_squared'] = df_A0['C1']*df_A0['C1']\n",
    "    df_A0['C1_sin'] = 3*np.sin(df_A0['C1'])\n",
    "    df_A0['C1_squared_sin_interaction'] = df_A0['C1_squared']*df_A0['C1_sin']\n",
    "    df_A1 = df_A0.copy()\n",
    "    df_A1['A'] = 1\n",
    "    mean_unexposed = MSM.predict(df_A0)[0]\n",
    "    mean_exposed = MSM.predict(df_A1)[0]\n",
    "    effect_difference = mean_exposed - mean_unexposed\n",
    "    \n",
    "    if(fit_bounds):\n",
    "        effect_difference_list = []\n",
    "        for i in range(0, 100):\n",
    "            df_sub = df.sample(n=df.shape[0], replace=True)\n",
    "            PS_model_sub = smf.glm(model_string, data=df_sub, family=sm.families.Binomial()).fit()\n",
    "            df_sub['Propensity_Score'] = PS_model_sub.predict(df_sub)\n",
    "            Marg_Prob_Intervention_sub = df_sub.loc[df_sub['A']==1, :].reset_index(drop=True).shape[0] / df_sub.shape[0]\n",
    "            df_sub['Unstabalized_Weights'] = None\n",
    "            df_sub.loc[df_sub['A']==1, 'Unstabalized_Weights'] = 1 / (df_sub.loc[df_sub['A']==1, 'Propensity_Score'])\n",
    "            df_sub.loc[df_sub['A']==0, 'Unstabalized_Weights'] = 1 / (1 - df_sub.loc[df_sub['A']==0, 'Propensity_Score'])\n",
    "            df_sub['Stabalized_Weights'] = None\n",
    "            df_sub.loc[df_sub['A']==1, 'Stabalized_Weights'] = (Marg_Prob_Intervention_sub) / (df_sub.loc[df_sub['A']==1, 'Propensity_Score'])\n",
    "            df_sub.loc[df_sub['A']==0, 'Stabalized_Weights'] = (1 - Marg_Prob_Intervention_sub) / (1 - df_sub.loc[df_sub['A']==0, 'Propensity_Score'])\n",
    "            MSM_sub = smf.wls(MSM_string, data=df_sub, weights=np.array(df_sub['Stabalized_Weights'], dtype=np.float64)).fit()\n",
    "            \n",
    "            df_A0_sub = pd.DataFrame()\n",
    "            df_A0_sub['A'] = [0]\n",
    "            df_A0_sub['C1'] = C1\n",
    "            df_A0_sub['C1_squared'] = df_A0_sub['C1']*df_A0_sub['C1']\n",
    "            df_A0_sub['C1_sin'] = 3*np.sin(df_A0_sub['C1'])\n",
    "            df_A0_sub['C1_squared_sin_interaction'] = df_A0_sub['C1_squared']*df_A0_sub['C1_sin']\n",
    "            df_A1_sub = df_A0_sub.copy()\n",
    "            df_A1_sub['A'] = 1\n",
    "            mean_unexposed_sub = MSM_sub.predict(df_A0_sub)[0]\n",
    "            mean_exposed_sub = MSM_sub.predict(df_A1_sub)[0]\n",
    "            effect_difference_sub = mean_exposed_sub - mean_unexposed_sub\n",
    "            \n",
    "            effect_difference_list.append(effect_difference_sub)\n",
    "            \n",
    "            del df_sub, PS_model_sub, Marg_Prob_Intervention_sub, MSM_sub, df_A0_sub, df_A1_sub, mean_unexposed_sub, mean_exposed_sub, effect_difference_sub\n",
    "    \n",
    "        variance = np.var(effect_difference_list)\n",
    "        standard_error = np.sqrt(variance)\n",
    "        bound_size = 1.96*standard_error\n",
    "        lower_bound = effect_difference - bound_size\n",
    "        upper_bound = effect_difference + bound_size\n",
    "\n",
    "    if(print_result):\n",
    "        print(MSM.summary())\n",
    "        print(\"The MSM mean in those with A=0 and C1=\" + str(C1) + \" is:\" + str(mean_unexposed))\n",
    "        print(\"The MSM mean in those with A=1 and C1=\" + str(C1) + \" is:\" + str(mean_exposed))\n",
    "        \n",
    "        if(fit_bounds):\n",
    "            print(\"The MSM effect difference with C1=\" + str(C1) +\" is \" + str(effect_difference) + \" with 95% CI (\" + str(lower_bound) + ' , ' + str(upper_bound) + ')')\n",
    "        else:\n",
    "            print(\"The MSM effect difference with C1=\" + str(C1) + \" is \" + str(effect_difference))\n",
    "        \n",
    "    return(df, MSM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            WLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                      Y   R-squared:                       0.999\n",
      "Model:                            WLS   Adj. R-squared:                  0.999\n",
      "Method:                 Least Squares   F-statistic:                 4.069e+07\n",
      "Date:                Tue, 15 Dec 2020   Prob (F-statistic):               0.00\n",
      "Time:                        12:34:39   Log-Likelihood:                -83887.\n",
      "No. Observations:              200000   AIC:                         1.678e+05\n",
      "Df Residuals:                  199993   BIC:                         1.679e+05\n",
      "Df Model:                           6                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================================\n",
      "                                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "----------------------------------------------------------------------------------------------\n",
      "Intercept                      0.0115      0.005      2.250      0.024       0.001       0.022\n",
      "A                              1.2329      0.004    278.595      0.000       1.224       1.242\n",
      "C1                             1.5588      0.005    299.886      0.000       1.549       1.569\n",
      "C1_squared                     1.4208      0.001   1010.505      0.000       1.418       1.424\n",
      "C1_sin                         2.3097      0.001   1852.826      0.000       2.307       2.312\n",
      "C1_squared_sin_interaction    -0.4297      0.000  -3045.901      0.000      -0.430      -0.429\n",
      "A:C1                           1.0887      0.002    663.417      0.000       1.086       1.092\n",
      "==============================================================================\n",
      "Omnibus:                     1314.575   Durbin-Watson:                   1.973\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):              942.294\n",
      "Skew:                           0.051   Prob(JB):                    2.42e-205\n",
      "Kurtosis:                       2.679   Cond. No.                         155.\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "The MSM mean in those with A=0 and C1=0.5 is:4.313550030446139\n",
      "The MSM mean in those with A=1 and C1=0.5 is:6.09085697872465\n",
      "The MSM effect difference with C1=0.5 is 1.777306948278511 with 95% CI (1.7703454953968965 , 1.7842684011601257)\n"
     ]
    }
   ],
   "source": [
    "## Inverse Probability Weighting via Marginal Structural Modeling, \n",
    "## with correctly specified Intervention model and Marginal Structural Model\n",
    "df_MSM_CS, MSM_CS = fit_MSM_model(df_original.copy(), model_string='A ~ C2', MSM_string='Y ~ A + C1 + C1_squared + C1_sin + C1_squared_sin_interaction + A*C1', C1=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            WLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                      Y   R-squared:                       0.781\n",
      "Model:                            WLS   Adj. R-squared:                  0.781\n",
      "Method:                 Least Squares   F-statistic:                 2.376e+05\n",
      "Date:                Tue, 15 Dec 2020   Prob (F-statistic):               0.00\n",
      "Time:                        12:38:48   Log-Likelihood:            -6.4287e+05\n",
      "No. Observations:              200000   AIC:                         1.286e+06\n",
      "Df Residuals:                  199996   BIC:                         1.286e+06\n",
      "Df Model:                           3                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "Intercept     -9.1624      0.046   -200.380      0.000      -9.252      -9.073\n",
      "A              1.0170      0.072     14.046      0.000       0.875       1.159\n",
      "C1            10.4399      0.017    614.747      0.000      10.407      10.473\n",
      "A:C1           1.1797      0.027     43.937      0.000       1.127       1.232\n",
      "==============================================================================\n",
      "Omnibus:                    61367.798   Durbin-Watson:                   1.999\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):           187728.767\n",
      "Skew:                           1.598   Prob(JB):                         0.00\n",
      "Kurtosis:                       6.509   Cond. No.                         19.9\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "The MSM mean in those with A=0 and C1=0.5 is:-3.9424716410817897\n",
      "The MSM mean in those with A=1 and C1=0.5 is:-2.335637389703326\n",
      "The MSM effect difference with C1=0.5 is 1.606834251378464 with 95% CI (1.4391229880423235 , 1.7745455147146043)\n"
     ]
    }
   ],
   "source": [
    "## Inverse Probability Weighting via Marginal Structural Modeling, \n",
    "## with incorrectly specified Intervention model and Marginal Structural Model\n",
    "df_MSM_CS, MSM_CS = fit_MSM_model(df_original.copy(), model_string='A ~ C2', MSM_string='Y ~ A + C1 + A*C1', C1=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################################\n",
    "## fit and return Strucutral Nested Model ##\n",
    "############################################\n",
    "\n",
    "def recover_psi_estimates(df_original, psi_1_bounds, psi_2_bounds, n=21):\n",
    "    psi_1_list = np.linspace(psi_1_bounds[0], psi_1_bounds[1], n)\n",
    "    psi_2_list = np.linspace(psi_2_bounds[0], psi_2_bounds[1], n)\n",
    "    df_results = pd.DataFrame()\n",
    "    df_results['psi_1'] = (n**2)*[None]\n",
    "    df_results['psi_2'] = None\n",
    "    df_results['coeff_Y_a0'] = None\n",
    "    df_results['coeff_Y_a0_C1'] = None\n",
    "    df_results['mean_error'] = None\n",
    "    i=0\n",
    "    for psi_1 in psi_1_list:\n",
    "        for psi_2 in psi_2_list:\n",
    "            df = df_original.copy()\n",
    "            df['Y_a0'] = df['Y'] - psi_1*df['A'] - psi_2*df['A']*df['C1']\n",
    "            df['Y_a0_C1'] = df['Y_a0']*df['C1']\n",
    "            PS_model = smf.glm('A ~ C2 + Y_a0 + Y_a0_C1', data=df, family=sm.families.Binomial()).fit()\n",
    "            df_results.loc[i, 'psi_1'] = psi_1\n",
    "            df_results.loc[i, 'psi_2'] = psi_2\n",
    "            df_results.loc[i, 'coeff_Y_a0'] = PS_model.params[2]\n",
    "            df_results.loc[i, 'coeff_Y_a0_C1'] = PS_model.params[3]\n",
    "            df_results.loc[i, 'mean_error'] = np.mean([abs(PS_model.params[2]), abs(PS_model.params[3])])\n",
    "            del df, PS_model\n",
    "            i = i+1\n",
    "    df_results = df_results.loc[df_results['mean_error']==min(df_results['mean_error']), :].reset_index(drop=True)\n",
    "    psi_1 = df_results.loc[0, 'psi_1']\n",
    "    psi_2 = df_results.loc[0, 'psi_2']    \n",
    "    return(psi_1, psi_2)\n",
    "\n",
    "def recover_SNM_with_bounds(df_original, psi_1_bounds, psi_2_bounds, C1=1, n=21, m=10):\n",
    "    psi_1, psi_2 = recover_psi_estimates(df_original, psi_1_bounds=psi_1_bounds, psi_2_bounds=psi_2_bounds, n=n)\n",
    "    ED = psi_1 + (psi_2*C1)\n",
    "    print(\"Recovered point-estimates of location parameters.\")\n",
    "    \n",
    "    psi_1_Boostrap = []\n",
    "    psi_2_Boostrap = []\n",
    "    ED_Boostrap = []\n",
    "    for i in range(0, m):\n",
    "        df_BS = df_original.sample(n=df_original.shape[0], replace=True)\n",
    "        psi_1_BS, psi_2_BS = recover_psi_estimates(df_BS, psi_1_bounds=psi_1_bounds, psi_2_bounds=psi_2_bounds, n=n)\n",
    "        ED_BS = psi_1_BS + (psi_2_BS*C1)\n",
    "        psi_1_Boostrap.append(psi_1_BS)\n",
    "        psi_2_Boostrap.append(psi_2_BS)\n",
    "        ED_Boostrap.append(ED_BS)\n",
    "        del df_BS, psi_1_BS, psi_2_BS, ED_BS\n",
    "        print(\"Completed \" + str(i+1) + \" Bootstrap Iteration.\")\n",
    "    \n",
    "    psi_1_se = np.sqrt(np.var(psi_1_Boostrap))\n",
    "    psi_2_se = np.sqrt(np.var(psi_2_Boostrap))\n",
    "    ED_se = np.sqrt(np.var(ED_Boostrap))\n",
    "    \n",
    "    psi_1 = np.mean(psi_1_Boostrap)\n",
    "    psi_2 = np.mean(psi_2_Boostrap)\n",
    "    ED = np.mean(ED_Boostrap)\n",
    "        \n",
    "    psi_1_lb = psi_1 - (1.96*psi_1_se)  \n",
    "    psi_1_ub = psi_1 + (1.96*psi_1_se) \n",
    "    psi_2_lb = psi_2 - (1.96*psi_2_se)  \n",
    "    psi_2_ub = psi_2 + (1.96*psi_2_se)\n",
    "    ED_lb = ED - (1.96*ED_se)  \n",
    "    ED_ub = ED + (1.96*ED_se)\n",
    "    \n",
    "    print('\\n')\n",
    "    print('The estimate for theta_1 is ' + str(psi_1) + ' with 95% CI (' + str(psi_1_lb) + ' , ' + str(psi_1_ub) + ')')\n",
    "    print('\\n')\n",
    "    print('The estimate for theta_6 is ' + str(psi_2) + ' with 95% CI (' + str(psi_2_lb) + ' , ' + str(psi_2_ub) + ')')\n",
    "    print('\\n')\n",
    "    print('The estimated Mean Causal Effect Difference under intervention a=1 and a=0 within levels of C1=' + str(C1) + ' is ' + str(ED) + ' with 95% CI (' + str(ED_lb) + ' , ' + str(ED_ub) + ')')\n",
    "\n",
    "    return(psi_1, [psi_1_lb, psi_1_ub], psi_2, [psi_2_lb, psi_2_ub])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recovered point-estimates of location parameters.\n",
      "Completed 1 Bootstrap Iteration.\n",
      "Completed 2 Bootstrap Iteration.\n",
      "Completed 3 Bootstrap Iteration.\n",
      "Completed 4 Bootstrap Iteration.\n",
      "Completed 5 Bootstrap Iteration.\n",
      "Completed 6 Bootstrap Iteration.\n",
      "Completed 7 Bootstrap Iteration.\n",
      "Completed 8 Bootstrap Iteration.\n",
      "Completed 9 Bootstrap Iteration.\n",
      "Completed 10 Bootstrap Iteration.\n",
      "Completed 11 Bootstrap Iteration.\n",
      "Completed 12 Bootstrap Iteration.\n",
      "Completed 13 Bootstrap Iteration.\n",
      "Completed 14 Bootstrap Iteration.\n",
      "Completed 15 Bootstrap Iteration.\n",
      "Completed 16 Bootstrap Iteration.\n",
      "Completed 17 Bootstrap Iteration.\n",
      "Completed 18 Bootstrap Iteration.\n",
      "Completed 19 Bootstrap Iteration.\n",
      "Completed 20 Bootstrap Iteration.\n",
      "Completed 21 Bootstrap Iteration.\n",
      "Completed 22 Bootstrap Iteration.\n",
      "Completed 23 Bootstrap Iteration.\n",
      "Completed 24 Bootstrap Iteration.\n",
      "Completed 25 Bootstrap Iteration.\n",
      "Completed 26 Bootstrap Iteration.\n",
      "Completed 27 Bootstrap Iteration.\n",
      "Completed 28 Bootstrap Iteration.\n",
      "Completed 29 Bootstrap Iteration.\n",
      "Completed 30 Bootstrap Iteration.\n",
      "Completed 31 Bootstrap Iteration.\n",
      "Completed 32 Bootstrap Iteration.\n",
      "Completed 33 Bootstrap Iteration.\n",
      "Completed 34 Bootstrap Iteration.\n",
      "Completed 35 Bootstrap Iteration.\n",
      "Completed 36 Bootstrap Iteration.\n",
      "Completed 37 Bootstrap Iteration.\n",
      "Completed 38 Bootstrap Iteration.\n",
      "Completed 39 Bootstrap Iteration.\n",
      "Completed 40 Bootstrap Iteration.\n",
      "Completed 41 Bootstrap Iteration.\n",
      "Completed 42 Bootstrap Iteration.\n",
      "Completed 43 Bootstrap Iteration.\n",
      "Completed 44 Bootstrap Iteration.\n",
      "Completed 45 Bootstrap Iteration.\n",
      "Completed 46 Bootstrap Iteration.\n",
      "Completed 47 Bootstrap Iteration.\n",
      "Completed 48 Bootstrap Iteration.\n",
      "Completed 49 Bootstrap Iteration.\n",
      "Completed 50 Bootstrap Iteration.\n",
      "Completed 51 Bootstrap Iteration.\n",
      "Completed 52 Bootstrap Iteration.\n",
      "Completed 53 Bootstrap Iteration.\n",
      "Completed 54 Bootstrap Iteration.\n",
      "Completed 55 Bootstrap Iteration.\n",
      "Completed 56 Bootstrap Iteration.\n",
      "Completed 57 Bootstrap Iteration.\n",
      "Completed 58 Bootstrap Iteration.\n",
      "Completed 59 Bootstrap Iteration.\n",
      "Completed 60 Bootstrap Iteration.\n",
      "Completed 61 Bootstrap Iteration.\n",
      "Completed 62 Bootstrap Iteration.\n",
      "Completed 63 Bootstrap Iteration.\n",
      "Completed 64 Bootstrap Iteration.\n",
      "Completed 65 Bootstrap Iteration.\n",
      "Completed 66 Bootstrap Iteration.\n",
      "Completed 67 Bootstrap Iteration.\n",
      "Completed 68 Bootstrap Iteration.\n",
      "Completed 69 Bootstrap Iteration.\n",
      "Completed 70 Bootstrap Iteration.\n",
      "Completed 71 Bootstrap Iteration.\n",
      "Completed 72 Bootstrap Iteration.\n",
      "Completed 73 Bootstrap Iteration.\n",
      "Completed 74 Bootstrap Iteration.\n",
      "Completed 75 Bootstrap Iteration.\n",
      "Completed 76 Bootstrap Iteration.\n",
      "Completed 77 Bootstrap Iteration.\n",
      "Completed 78 Bootstrap Iteration.\n",
      "Completed 79 Bootstrap Iteration.\n",
      "Completed 80 Bootstrap Iteration.\n",
      "Completed 81 Bootstrap Iteration.\n",
      "Completed 82 Bootstrap Iteration.\n",
      "Completed 83 Bootstrap Iteration.\n",
      "Completed 84 Bootstrap Iteration.\n",
      "Completed 85 Bootstrap Iteration.\n",
      "Completed 86 Bootstrap Iteration.\n",
      "Completed 87 Bootstrap Iteration.\n",
      "Completed 88 Bootstrap Iteration.\n",
      "Completed 89 Bootstrap Iteration.\n",
      "Completed 90 Bootstrap Iteration.\n",
      "Completed 91 Bootstrap Iteration.\n",
      "Completed 92 Bootstrap Iteration.\n",
      "Completed 93 Bootstrap Iteration.\n",
      "Completed 94 Bootstrap Iteration.\n",
      "Completed 95 Bootstrap Iteration.\n",
      "Completed 96 Bootstrap Iteration.\n",
      "Completed 97 Bootstrap Iteration.\n",
      "Completed 98 Bootstrap Iteration.\n",
      "Completed 99 Bootstrap Iteration.\n",
      "Completed 100 Bootstrap Iteration.\n",
      "Completed 101 Bootstrap Iteration.\n",
      "Completed 102 Bootstrap Iteration.\n",
      "Completed 103 Bootstrap Iteration.\n",
      "Completed 104 Bootstrap Iteration.\n",
      "Completed 105 Bootstrap Iteration.\n",
      "Completed 106 Bootstrap Iteration.\n",
      "Completed 107 Bootstrap Iteration.\n",
      "Completed 108 Bootstrap Iteration.\n",
      "Completed 109 Bootstrap Iteration.\n",
      "Completed 110 Bootstrap Iteration.\n",
      "Completed 111 Bootstrap Iteration.\n",
      "Completed 112 Bootstrap Iteration.\n",
      "Completed 113 Bootstrap Iteration.\n",
      "Completed 114 Bootstrap Iteration.\n",
      "Completed 115 Bootstrap Iteration.\n",
      "Completed 116 Bootstrap Iteration.\n",
      "Completed 117 Bootstrap Iteration.\n",
      "Completed 118 Bootstrap Iteration.\n",
      "Completed 119 Bootstrap Iteration.\n",
      "Completed 120 Bootstrap Iteration.\n",
      "Completed 121 Bootstrap Iteration.\n",
      "Completed 122 Bootstrap Iteration.\n",
      "Completed 123 Bootstrap Iteration.\n",
      "Completed 124 Bootstrap Iteration.\n",
      "Completed 125 Bootstrap Iteration.\n",
      "Completed 126 Bootstrap Iteration.\n",
      "Completed 127 Bootstrap Iteration.\n",
      "Completed 128 Bootstrap Iteration.\n",
      "Completed 129 Bootstrap Iteration.\n",
      "Completed 130 Bootstrap Iteration.\n",
      "Completed 131 Bootstrap Iteration.\n",
      "Completed 132 Bootstrap Iteration.\n",
      "Completed 133 Bootstrap Iteration.\n",
      "Completed 134 Bootstrap Iteration.\n",
      "Completed 135 Bootstrap Iteration.\n",
      "Completed 136 Bootstrap Iteration.\n",
      "Completed 137 Bootstrap Iteration.\n",
      "Completed 138 Bootstrap Iteration.\n",
      "Completed 139 Bootstrap Iteration.\n",
      "Completed 140 Bootstrap Iteration.\n",
      "Completed 141 Bootstrap Iteration.\n",
      "Completed 142 Bootstrap Iteration.\n",
      "Completed 143 Bootstrap Iteration.\n",
      "Completed 144 Bootstrap Iteration.\n",
      "Completed 145 Bootstrap Iteration.\n",
      "Completed 146 Bootstrap Iteration.\n",
      "Completed 147 Bootstrap Iteration.\n",
      "Completed 148 Bootstrap Iteration.\n",
      "Completed 149 Bootstrap Iteration.\n",
      "Completed 150 Bootstrap Iteration.\n",
      "Completed 151 Bootstrap Iteration.\n",
      "Completed 152 Bootstrap Iteration.\n",
      "Completed 153 Bootstrap Iteration.\n",
      "Completed 154 Bootstrap Iteration.\n",
      "Completed 155 Bootstrap Iteration.\n",
      "Completed 156 Bootstrap Iteration.\n",
      "Completed 157 Bootstrap Iteration.\n",
      "Completed 158 Bootstrap Iteration.\n",
      "Completed 159 Bootstrap Iteration.\n",
      "Completed 160 Bootstrap Iteration.\n",
      "Completed 161 Bootstrap Iteration.\n",
      "Completed 162 Bootstrap Iteration.\n",
      "Completed 163 Bootstrap Iteration.\n",
      "Completed 164 Bootstrap Iteration.\n",
      "Completed 165 Bootstrap Iteration.\n",
      "Completed 166 Bootstrap Iteration.\n",
      "Completed 167 Bootstrap Iteration.\n",
      "Completed 168 Bootstrap Iteration.\n",
      "Completed 169 Bootstrap Iteration.\n",
      "Completed 170 Bootstrap Iteration.\n",
      "Completed 171 Bootstrap Iteration.\n",
      "Completed 172 Bootstrap Iteration.\n",
      "Completed 173 Bootstrap Iteration.\n",
      "Completed 174 Bootstrap Iteration.\n",
      "Completed 175 Bootstrap Iteration.\n",
      "Completed 176 Bootstrap Iteration.\n",
      "Completed 177 Bootstrap Iteration.\n",
      "Completed 178 Bootstrap Iteration.\n",
      "Completed 179 Bootstrap Iteration.\n",
      "Completed 180 Bootstrap Iteration.\n",
      "Completed 181 Bootstrap Iteration.\n",
      "Completed 182 Bootstrap Iteration.\n",
      "Completed 183 Bootstrap Iteration.\n",
      "Completed 184 Bootstrap Iteration.\n",
      "Completed 185 Bootstrap Iteration.\n",
      "Completed 186 Bootstrap Iteration.\n",
      "Completed 187 Bootstrap Iteration.\n",
      "Completed 188 Bootstrap Iteration.\n",
      "Completed 189 Bootstrap Iteration.\n",
      "Completed 190 Bootstrap Iteration.\n",
      "Completed 191 Bootstrap Iteration.\n",
      "Completed 192 Bootstrap Iteration.\n",
      "Completed 193 Bootstrap Iteration.\n",
      "Completed 194 Bootstrap Iteration.\n",
      "Completed 195 Bootstrap Iteration.\n",
      "Completed 196 Bootstrap Iteration.\n",
      "Completed 197 Bootstrap Iteration.\n",
      "Completed 198 Bootstrap Iteration.\n",
      "Completed 199 Bootstrap Iteration.\n",
      "Completed 200 Bootstrap Iteration.\n",
      "\n",
      "\n",
      "The estimate for theta_1 is 1.2502000000000002 with 95% CI (1.1728865087064362 , 1.3275134912935642)\n",
      "\n",
      "\n",
      "The estimate for theta_6 is 1.0817999999999999 with 95% CI (1.047137357054027 , 1.1164626429459727)\n",
      "\n",
      "\n",
      "The estimated Mean Causal Effect Difference under intervention a=1 and a=0 within levels of C1=0.5 is 1.7911 with 95% CI (1.7296237634203262 , 1.8525762365796736)\n"
     ]
    }
   ],
   "source": [
    "## Fit Structural Nested Model\n",
    "theta_1, theta_1_95CI, theta_6, theta_6_95CI = recover_SNM_with_bounds(df_original, psi_1_bounds=[1.2, 1.3], psi_2_bounds=[1, 1.1], C1=0.5, n=6, m=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf_gpu",
   "language": "python",
   "name": "tf_gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
